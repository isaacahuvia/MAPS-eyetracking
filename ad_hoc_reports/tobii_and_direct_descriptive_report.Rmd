---
title: "Tobii and Direct Indicators Descriptive Report v3"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
---

```{r, include = F}
library(easypackages)
libraries("yaml", "ggplot2", "magrittr", "ggpubr", "eyetrackingR", "openxlsx", "knitr", "kableExtra", "cowplot", "magick", "plyr", "tidyverse", "conflicted", "purrr", "corrplot", "interactions", "zoo")
walk(c("filter", "count", "group_by", "summarise", "summarize", "mutate", "select", "arrange"),
     ~ conflict_prefer(., "dplyr"))

knitr::opts_chunk$set(echo = F, message = F, fig.align = "center")

rm(list = ls())

filenames <- yaml::read_yaml("C:\\Users\\isaac\\Box\\MAPS - ECHO Tobii Analysis\\MAPS-eyetracking\\filenames.yaml")

## Load Data
df <- readRDS(filenames$analysis_ready)
tobii.item <- readRDS(filenames$tobii$clean_data$item_level)
tobii.participant <- readRDS(filenames$tobii$clean_data$participant_level)

questions <- as.data.frame(
  sapply(
    read.xlsx(filenames$tobii$qID_lookup),
    trimws),
  stringsAsFactors = F)

## Set functions
pValue <- function(x) {
  x <- as.numeric(x)
  if(x < .01) {
    y = "<0.01"
  } else {
    y = round(x, 2)
  }
  return(y)
}
```

# Part 1: Tobii Descriptive Analysis

This report includes eye-tracking statistics for the complete MAPS - ECHO sample. The report covers the following areas:

(1) Average response time by participant,
(2) Average time spent looking at the question text by participant, and
(3) Average response time and time spent looking at the question text by response selection.

The report furthermore includes an analysis of (1) and (2) for items with the most variation in response- and gaze-time. Lastly, section (3) explores the hypothesis that participants take longer to read the question text on items where they do not answer in the extremes.

*Sample*

The sample for this analysis is not limited by percentage of valid eyetracking samples. There are `r nrow(tobii.participant)` participants in the Tobii sample. Items where participants took more than 90 seconds to respond were removed.

\newpage

### Average Response Time by Participant

```{r, include = F}
lessThan5 = round(mean(tobii.participant$dur.tot < 5), 2)
min = round(min(tobii.participant$dur.tot), 1)
avg = round(mean(tobii.participant$dur.tot), 1)
```

The lowest average response time was `r min` seconds, while the average was `r avg` seconds. Some in the literature have suggested that a useful cutoff for average response time (under which responses should be treated as invalid) should be approximately 2 seconds. One reason why our questions take longer to respond to, and why this cutoff might not apply here, has to do with how they are presented. In Tobii, questions are presented one at a time, and the participant must hit submit before seeing the next question. This can take much longer than questionnaires where items are presented in rows on the same page and respondents can merely scroll through. This 2 second benchmark was also developed with an adult sample.

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
ggplot(tobii.participant) +
  geom_density(aes(dur.tot)) +
  geom_point(aes(x = dur.tot, y = 0), size = 2) +
  xlim(0, 25) + ylim(0, .5) +
  xlab("Average Response Time (Seconds)") + ylab("Density") +
  theme_classic()
```

I removed questions where the duration was over 90 seconds, as these are likely times when the participant took a break during the survey. The two outliers in this plot (3969 and 4203) are participants who took a very long time for nearly every question.

\newpage

### Average Response Time by Participant - 10 Highest-Variance Items

The following plot includes the same metric, but only across the 10 items with the largest standard deviation in response time.

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
topItems <- tobii.item %>%
  group_by(qID) %>%
  summarise(sd = sd(dur.tot)) %>%
  arrange(-sd) %>%
  select(qID) %>%
  head(10)

tobii.participant_subset <- tobii.item %>%
  filter(qID %in% topItems$qID) %>%
  group_by(participantID) %>%
  summarise(dur.tot = mean(dur.tot),
                   dur.qText = mean(dur.qText))

ggplot(tobii.participant_subset) +
  geom_density(aes(dur.tot)) +
  geom_point(aes(x = dur.tot, y = 0), size = 2) +
  xlim(0, 25) + ylim(0, .5) +
  xlab("Average Response Time (Seconds) - Highest-Variance Items") + ylab("Density") +
  theme_classic()
```

And here are those items:

```{r, warning = F}
questions_subset <- questions[questions$qID %in% topItems$qID,] %>%
  arrange(qID) %>%
  select(qID, qText)

cutoff = 175
for(i in 1:nrow(questions_subset)) {
  if(nchar(questions_subset$qText[i]) > cutoff) {
    a <- substr(questions_subset$qText[i], 1, cutoff)
    b <- "..."
    questions_subset$qText[i] <- paste0(a, b)
  }
}
kable(questions_subset,
      booktabs = T) %>%
  column_spec(2, "5.5in") %>%
  kable_styling(latex_options = "basic",
                position = "center")
```

\newpage

### Average Response Time by Participant, by Measure

```{r, warning = F, fig.height = 7.5, fig.width = 5.25}
tobii.item %>%
  group_by(participantID, measure) %>%
  summarise(dur.tot = mean(dur.tot),
                   dur.qText = mean(dur.qText)) %>%
  ggplot() +
  geom_density(aes(dur.tot)) +
  geom_point(aes(x = dur.tot, y = 0), size = 2) +
  geom_vline(data = ddply(tobii.item, "measure", summarize, dur.tot = mean(dur.tot)), aes(xintercept = dur.tot)) +
  xlim(0, 25) + ylim(0, .5) +
  xlab("Average Response Time (Seconds)") + ylab("Density") +
  theme_classic() +
  facet_grid(rows = vars(measure))
```

*Key*
A: Anger
F: Fatigue
GH: Global Health
PA: Physical Activity
PFR: Family Relationships
PSE: Psychological Stress

\newpage

### Average Response Time by Participant - Additional Metrics

#### Percent of questions taking _less than_ 4 seconds

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
df %>%
  ggplot() +
    geom_density(aes(tobii.pctUnder4Sec)) +
    geom_point(aes(x = tobii.pctUnder4Sec, y = 0), size = 2) +
    scale_x_continuous(name = "Percent of Questions Taking <4 Seconds", limits = c(0, 1), labels = scales::percent) +
    scale_y_continuous(name = "Density", labels = NULL, breaks = NULL) +
    theme_classic()
```

#### Standard deviation of response time

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
df %>%
  ggplot() +
    geom_density(aes(tobii.avgQuestionDuration_sd)) +
    geom_point(aes(x = tobii.avgQuestionDuration_sd, y = 0), size = 2) +
    scale_x_continuous(name = "Response Time Standard Deviation") +
    scale_y_continuous(name = "Density", labels = NULL, breaks = NULL) +
    theme_classic()
```

\newpage

### Average Time Looking at Question Text by Participant

```{r, include = F}
qTextAvg = round(mean(tobii.participant$dur.qText), 1)
lessThan0.5 = round(mean(tobii.participant$dur.qText < .5), 2)
lessThan0.1 = round(mean(tobii.participant$dur.qText < .1), 2)
```

The average fixation time on the question text was `r qTextAvg` seconds. `r lessThan0.5` of participants fixated on the question text for less than .5 seconds on average.

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
ggplot(tobii.participant) +
  geom_density(aes(dur.qText)) +
  geom_point(aes(x = dur.qText, y = 0), size = 2) +
  xlim(0, 10) + ylim(0, 1) +
  xlab("Fixation Duration - Question Text (Seconds)") + ylab("Density") +
  theme_classic()
```

\newpage

### Average Time Looking at Question Text by Participant

The following plot includes the same metric, but only across the 10 items with the largest standard deviation in time spent looking at question text.

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
topItems <- tobii.item %>%
  group_by(qID) %>%
  summarise(sd = sd(dur.qText)) %>%
  arrange(-sd) %>%
  select(qID) %>%
  head(10)

tobii.participant_subset <- tobii.item %>%
  filter(qID %in% topItems$qID) %>%
  group_by(participantID) %>%
  summarise(dur.tot = mean(dur.tot),
                   dur.qText = mean(dur.qText))

ggplot(tobii.participant_subset) +
  geom_density(aes(dur.qText)) +
  geom_point(aes(x = dur.qText, y = 0), size = 2) +
  xlim(0, 25) + ylim(0, 1) +
  xlab("Average Fixation Time (Seconds) - Highest-Variance Items") + ylab("Density") +
  theme_classic()
```

And here are those items:

```{r, warning = F}
questions_subset <- questions[questions$qID %in% topItems$qID,] %>%
  arrange(qID) %>%
  select(qID, qText)

cutoff = 175
for(i in 1:nrow(questions_subset)) {
  if(nchar(questions_subset$qText[i]) > cutoff) {
    a <- substr(questions_subset$qText[i], 1, cutoff)
    b <- "..."
    questions_subset$qText[i] <- paste0(a, b)
  }
}
kable(questions_subset,
      booktabs = T) %>%
  column_spec(2, "5.5in") %>%
  kable_styling(latex_options = "basic",
                position = "center")
```

\newpage

### Average Time Looking at Question Text by Participant, by Measure

```{r, warning = F, fig.height = 7.5, fig.width = 5.25}
tobii.item %>%
  group_by(participantID, measure) %>%
  summarise(dur.tot = mean(dur.tot),
                   dur.qText = mean(dur.qText)) %>%
  ggplot() +
  geom_density(aes(dur.qText)) +
  geom_point(aes(x = dur.qText, y = 0), size = 2) +
  geom_vline(data = ddply(tobii.item, "measure", summarize, dur.qText = mean(dur.qText)), aes(xintercept = dur.qText)) +
  xlim(0, 10) + ylim(0, 1) +
  xlab("Average Fixation Time (Seconds)") + ylab("Density") +
  theme_classic() +
  facet_grid(rows = vars(measure))
```

*Key*
A: Anger
F: Fatigue
GH: Global Health
PA: Physical Activity
PFR: Family Relationships
PSE: Psychological Stress

\newpage

### Average Time Looking at Question Text by Participant - Additional Metrics

#### Standard deviation of gaze time

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
df %>%
  ggplot() +
    geom_density(aes(tobii.avgQTextFixationTime_sd)) +
    geom_point(aes(x = tobii.avgQTextFixationTime_sd, y = 0), size = 2) +
    scale_x_continuous(name = "Fixation Time Standard Deviation") +
    scale_y_continuous(name = "Density", labels = NULL, breaks = NULL) +
    theme_classic()
```


\newpage

### Average Response Time and Average Time Looking at Question Text by Type of Response

```{r, warning = F, fig.height = 4, fig.width = 5}
#ADD AGE
model.tot <- summary(lm(data = tobii.item, dur.tot ~ extremeFlag))

tobii.item %>%
  group_by(extremeFlag) %>%
  summarise(mean = mean(dur.tot)) %>%
  ggplot() +
  geom_bar(aes(extremeFlag, mean), stat = "identity") +
  scale_x_discrete(name = "Type of Response", labels = c("Not Extreme", "Extreme")) +
  scale_y_continuous(name = "Question Duration (Seconds)") +
  labs(title = "Average Response Time by Type of Response") +
  theme_classic()

kable(model.tot$coefficients, 
      digits = 2,
      booktabs = T) %>%
  kable_styling(latex_options = "basic",
                position = "center")
```

```{r, warning = F, fig.height = 4, fig.width = 5}
model.qTextWithControl <- summary(lm(data = tobii.item, dur.qText ~ extremeFlag + pctValidGazeSamples))

tobii.item %>%
  group_by(extremeFlag) %>%
  summarise(mean = mean(dur.qText)) %>%
  ggplot() +
  geom_bar(aes(extremeFlag, mean), stat = "identity") +
  scale_x_discrete(name = "Type of Response", labels = c("Not Extreme", "Extreme")) +
  scale_y_continuous(name = "Time Spent Looking at Question Text (Seconds)") +
  labs(title = "Average Time Spent Looking at 
Question Text by Type of Response") +
  theme_classic()

kable(model.qTextWithControl$coefficients, 
      digits = 2,
      booktabs = T) %>%
  kable_styling(latex_options = "basic",
                position = "center")
```

\newpage

### Average Response Time and Average Time Looking at Question Text by Position of Item in Survey

Total time spent on question over time: 

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
tobii.item %>%
  group_by(qIndex) %>%
  summarise(dur.tot = mean(dur.tot, na.rm = T)) %>%
  ggplot() +
  geom_line(aes(qIndex, dur.tot)) +
  geom_smooth(aes(qIndex, dur.tot), method = "lm") +
  scale_x_continuous(name = "Question Index") +
  scale_y_continuous(name = "Average Response Time (Seconds)", limits = c(0, 15)) +
  theme_classic()
```

Time spent looking at question text over time: 

```{r, warning = F, fig.height = 3.75, fig.width = 5.25}
tobii.item %>%
  group_by(qIndex) %>%
  summarise(dur.qText = mean(dur.qText, na.rm = T)) %>%
  ggplot() +
  geom_line(aes(qIndex, dur.qText)) +
  geom_smooth(aes(qIndex, dur.qText), method = "lm") +
  scale_x_continuous(name = "Question Index") +
  scale_y_continuous(name = "Average Fixation Time (Seconds)", limits = c(0, 4)) +
  theme_classic()
```

\newpage

# Part 2: Tobii, Woodcock-Johnson, and Direct Indicators

In the latter stage of the study, we began to collect direct indicators of self-report validity from participants. On the whole, we collected any direct indicator from 84 participants, and a complete set of direct indicators from 66 participants. Of the 84 participants who completed any direct self-report measure, 39 completed Tobii eye-tracking procedures. As such, we have up to 39 (34 if we only count those with complete direct measure data) participants with which to conduct these analyses.

## Measure overview

### Direct indicators

In addition to reading level and eye-tracking data, we collected 4 direct indicators of self-report validity:

* Instructed items: Two items with prompts like "please select "Strongly Agree" for this item"

```{r, warning = F, fig.height = 2}
df %>%
  count(instructed) %>%
  filter(!is.na(instructed)) %>%
  ggplot(aes(instructed, n)) +
    geom_bar(stat = "identity") +
    scale_x_continuous(name = "Number of Instructed Items Failed") +
    scale_y_continuous(name = "Count")
```

* Recall items: Two items that asked about the contents of previous questions

```{r, warning = F, fig.height = 2}
df %>%
  count(recall) %>%
  filter(!is.na(recall)) %>%
  ggplot(aes(recall, n)) +
    geom_bar(stat = "identity") +
    scale_x_continuous(name = "Number of Recall Items Failed") +
    scale_y_continuous(name = "Count")
```

\newpage 

* Effort items: Two items that asked how much effort and attention the participant put in, asked at the end of the questionnaire. "Failure" is defined as reporting the lowest or second-lowest amount of effort/attention.

```{r, warning = F, fig.height = 2}
df %>%
  count(effort) %>%
  filter(!is.na(effort)) %>%
  ggplot(aes(effort, n)) +
    geom_bar(stat = "identity") +
    scale_x_continuous(name = "Number of Effort Items Failed") +
    scale_y_continuous(name = "Count")
```

* The "rum raisin" scale: A set of innocuous questions meant to identify participants answering "mischeviously" (e.g. a participant is asked how many siblings they have, and answering "more than 10" is flagged)

```{r, warning = F, fig.height = 2}
df %>%
  count(rumRaisin) %>%
  filter(!is.na(rumRaisin)) %>%
  ggplot(aes(rumRaisin, n)) +
    geom_bar(stat = "identity") +
    scale_x_continuous(name = "Number of Rum Raisin Items Failed", limits = c(-.5, 2.5), breaks = c(0, 1, 2), labels = c("0", "1", "2+")) +
    scale_y_continuous(name = "Count")
```

Each item was given a value of 0-2 as per above, and combined into a single measure with values of 0-8.

```{r, warning = F, fig.height = 2.5}
df %>%
  count(direct) %>%
  filter(!is.na(direct)) %>%
  ggplot(aes(direct, n)) +
    geom_bar(stat = "identity") +
    scale_x_continuous(name = "Direct Indicators Score", limits = c(-.5, 8.5), breaks = seq(0, 8, 1)) +
    scale_y_continuous(name = "Count", limits = c(0, 25), breaks = seq(0, 25, 5))
```

\newpage

### Tobii indicators

We use measures of (a) average fixation time _on the question text_ and (b) a measure of total question duration (regardless of gaze).

```{r, warning = F, fig.height = 2.5}
df %>%
  gather("measure", "duration", tobii.avgQuestionDuration:tobii.avgQTextFixationTime) %>%
  ggplot(aes(duration)) +
    geom_histogram(binwidth = .25, color = "white") +
    scale_x_continuous(name = "Duration") +
    scale_y_continuous(name = "Count", limits = c(0, 25), breaks = seq(0, 25, 5)) +
    facet_grid(. ~ measure, scales = "free")
```

### Reading level

Raw scores to Woodcock-Johnson measures of reading ability:

* Letter-Word ID
* Passage Completion
* Reading Fluency

```{r, warning = F, fig.height = 2.5}
df %>%
  gather("measure", "score", wj.letterWordID.rawScore:wj.readingFluency.rawScore) %>%
  filter(score >= 400,
         score <= 600) %>%
  ggplot(aes(score)) +
    geom_histogram(binwidth = 10, color = "white") +
    scale_x_continuous(name = "Raw Score", limits = c(400, 600), breaks = seq(400, 600, 50)) +
    scale_y_continuous(name = "Count", limits = c(0, 50), breaks = seq(0, 50, 10)) +
    facet_grid(. ~ measure)
```

\newpage 

# Correlations 

### Correlation Plot for all of the measures previously discussed

```{r, echo = F, warning = F}
df %>%
  select(`Letter-Word ID` = wj.letterWordID.rawScore,
         `Passage Comp` = wj.passageCompletion.rawScore,
         `Reading Fluency` = wj.readingFluency.rawScore,
         `NEPSY: Duration` = nepsy.duration,
         `NEPSY: Uncorrected` = nepsy.uncorrectedErrors,
         `NEPSY: Corrected` = nepsy.selfCorrectedErrors,
         `NEPSY: Tot Errors` = nepsy.totalErrors,
         `Instructed Items` = instructed,
         `Recall Items` = recall,
         `Rum Raisin` = rumRaisin,
         `Effort Items` = effort,
         `Omitted Items` = omittedItems,
         `Mahalanobis D` = mahalanobisDist,
         `Longstring` = longstring,
         `Guttman` = polyGuttmanErrors,
         `Person Total Cor` = personTotalCor, 
         `Psych Synonyms` = psychSyn, 
         `Resampled Consistency` = resampledConsistency,
         `Reversed Item Diff` = reversedItemDifference,
         `U3` = u3,
         `Z-score` = zScore,
         `APSS_CAPE > 2` = infreqSymptoms,
         `Avg Count FIxations` = meanFixations,
         `Fixation Time` = tobii.avgQTextFixationTime,
         `Fixation Time: SD` = tobii.avgQTextFixationTime_sd,
         `Fixation Time: z` = tobii.avgQTextFixationTime_z,
         `Question Duration` = tobii.avgQuestionDuration,
         `Question Duration: SD` = tobii.avgQuestionDuration_sd,
         `Question Duration: z` = tobii.avgQuestionDuration_z,
         `Pct < 4 Sec` = tobii.pctUnder4Sec) %>%
  cor(use = "pairwise.complete.obs") %>%
  corrplot(type = "full", order = "original", tl.col = "black", tl.cex = .6)
```

\newpage

### Descriptive Statistics for All Variables in Corrplot

```{r, echo = F}
df %>%
  select(participantID, 
         `Letter-Word ID` = wj.letterWordID.rawScore,
         `Passage Comp` = wj.passageCompletion.rawScore,
         `Reading Fluency` = wj.readingFluency.rawScore,
         `NEPSY: Duration` = nepsy.duration,
         `NEPSY: Uncorrected` = nepsy.uncorrectedErrors,
         `NEPSY: Corrected` = nepsy.selfCorrectedErrors,
         `NEPSY: Tot Errors` = nepsy.totalErrors,
         `Instructed Items` = instructed,
         `Recall Items` = recall,
         `Rum Raisin` = rumRaisin,
         `Effort Items` = effort,
         `Omitted Items` = omittedItems,
         `Mahalanobis D` = mahalanobisDist,
         `Longstring` = longstring,
         `Guttman` = polyGuttmanErrors,
         `Person Total Cor` = personTotalCor, 
         `Psych Synonyms` = psychSyn, 
         `Resampled Consistency` = resampledConsistency,
         `Reversed Item Diff` = reversedItemDifference,
         `U3` = u3,
         `Z-score` = zScore,
         `APSS_CAPE > 2` = infreqSymptoms,
         `Fixation Time` = tobii.avgQTextFixationTime,
         `Fixation Time: SD` = tobii.avgQTextFixationTime_sd,
         `Fixation Time: z` = tobii.avgQTextFixationTime_z,
         `Question Duration` = tobii.avgQuestionDuration,
         `Question Duration: SD` = tobii.avgQuestionDuration_sd,
         `Question Duration: z` = tobii.avgQuestionDuration_z,
         `Pct < 4 Sec` = tobii.pctUnder4Sec) -> temp
temp %>%
  pivot_longer(-participantID, names_to = "Variable", values_to = "Values") %>%
  group_by(Variable) %>%
  summarise(nonmissing = mean(!is.na(Values)),
            min = min(Values, na.rm = T),
            max = max(Values, na.rm = T),
            mean = mean(Values, na.rm = T),
            sd = sd(Values, na.rm = T)) %>%
  arrange(match(Variable, names(temp))) %>%
  knitr::kable(booktabs = T, digits = 2)
```

\newpage

### Indirect Indicators Over Time

We can calculate longstring and inter-item SD over time/at different points in the survey. We can also calculate the number of extreme response choices they endorse. Here we calculate those measures for each question (starting with the 20th) for the previous 20 responses. This is how these measures vary over time as participants go through the survey:

```{r, echo = F}
tobii.temp <- tobii.item %>%
  select(participantID, qID, qIndex) %>%
  mutate(qID = gsub(" ", "_", qID))

redcap.temp <- df %>%
  select(participantID, PROMIS_PFR_Q1:c6mapdb113) %>%
  pivot_longer(PROMIS_PFR_Q1:c6mapdb113,
               names_to = "qID") %>%
  mutate(participantID = as.character(participantID))

temp <- inner_join(tobii.temp, redcap.temp, by = c("participantID", "qID")) %>%
  select(-qID) %>%
  arrange(qIndex) %>%
  pivot_wider(id_cols = participantID,
              names_from = qIndex,
              names_prefix = "q",
              values_from = value)

source("C:\\Users\\isaac\\Box\\MAPS - ECHO Tobii Analysis\\MAPS-eyetracking\\redcap_data_cleaning\\archival_indicators_functions.R")

x <- list()
for(i in 1:(length(temp) - 20)) x[[i]] <- c(i:(i+19))

longstringOverTime <- x %>%
  map(~ longstring(temp,
                   columns = .) %>%
        mean()) %>%
  unlist()

interItemSDOverTime <- x %>%
  map(~ interItemSD(temp,
                    columns = .) %>%
        mean(na.rm = T)) %>%
  unlist()
```

```{r, echo = F, warning = F}
data.frame(
  qIndex = 20:(length(temp)-1),
  longString = longstringOverTime
) %>%
  ggplot() +
    geom_point(aes(qIndex, longString)) +
    scale_x_continuous(name = "Question Index") +
    scale_y_continuous(name = "Average Longstring\n(Previous 20 Questions)",
                       limits = c(0, 10)) +
    ggtitle("Rolling Longstring Over Time")
```

```{r, echo = F, warning = F}
data.frame(
  qIndex = 20:(length(temp)-1),
  interItemSD = interItemSDOverTime
) %>%
  ggplot() +
    geom_point(aes(qIndex, interItemSD)) +
    scale_x_continuous(name = "Question Index") +
    scale_y_continuous(name = "Average Inter-Item SD\n(Previous 20 Questions)",
                       limits = c(0, 1.5)) +
    ggtitle("Rolling Inter-Item SD Over Time")
```

\newpage 

Also, here's how extreme answering changes over time using the same method:

```{r, echo = F, warning = F}
tobii.item %>%
  group_by(qIndex) %>%
  summarise(extreme = mean(extremeFlag)) %>%
  mutate(runningAvg = zoo::rollmean(extreme,
                                    k = 20,
                                    fill = NA,
                                    align = "right")) %>% 
  ggplot() +
    geom_point(aes(qIndex, runningAvg)) +
    scale_x_continuous(name = "Question Index") +
    scale_y_continuous(name = "Percent Extreme Responses\n(Previous 20 Questions)",
                       limits = c(0, 1),
                       labels = scales::percent_format())
```

\newpage

### Direct indicators and reading level

```{r, warning = F, fig.height = 3}
df %>%
  gather(key = "measure", value = "Score", starts_with("wj")) %>%
  filter(Score >= 400,
         Score <= 600) %>%
  mutate(measure = case_when(measure == "wj.letterWordID.rawScore"      ~ "WJ - Letter-Word ID",
                             measure == "wj.passageCompletion.rawScore" ~ "WJ - Passage Completion",
                             measure == "wj.readingFluency.rawScore"    ~ "WJ - Reading Fluency")) %>%
  ggplot(aes(Score, direct)) +
    geom_point() +
    geom_smooth(method = "lm") +
    stat_cor() +
    scale_x_continuous(name = "Standard Score") +
    scale_y_continuous(name = "Direct Indicators Score", limits = c(0, 4)) +
    facet_grid(. ~ measure)
``` 

### Tobii indicators and direct indicators

```{r, warning = F, fig.height = 3}
df %>%
  gather(key = "tobii_indicator", value = "Duration", c("tobii.avgQTextFixationTime", "tobii.avgQuestionDuration")) %>%
  mutate(tobii_indicator = case_when(tobii_indicator == "tobii.avgQTextFixationTime" ~ "Average Question Text Fixation",
                                     tobii_indicator == "tobii.avgQuestionDuration"  ~ "Average Question Duration (Overall)")) %>%
  ggplot(aes(Duration, direct)) +
    geom_point() +
    geom_smooth(method = "lm") +
    stat_cor() +
    scale_x_continuous(name = "Duration (Seconds)") +
    scale_y_continuous(name = "Direct Indicators Score", limits = c(0, 4)) +
    facet_grid(. ~ tobii_indicator, scales = "free_x")
```

\newpage

### Tobii indicators and reading level

```{r, warning = F, fig.height = 6}
df %>%
  gather(key = "measure", value = "Score", starts_with("wj")) %>%
  filter(Score >= 400,
         Score <= 600) %>%
  gather(key = "tobii_indicator", value = "Duration", c("tobii.avgQTextFixationTime", "tobii.avgQuestionDuration")) %>%
  mutate(tobii_indicator = case_when(tobii_indicator == "tobii.avgQTextFixationTime" ~ "Average Question Text Fixation",
                                     tobii_indicator == "tobii.avgQuestionDuration"  ~ "Average Question Duration (Overall)"),
         measure = case_when(measure == "wj.letterWordID.rawScore"      ~ "WJ - Letter-Word ID",
                             measure == "wj.passageCompletion.rawScore" ~ "WJ - Passage Completion",
                             measure == "wj.readingFluency.rawScore"    ~ "WJ - Reading Fluency")) %>%
  ggplot(aes(Duration, Score)) +
    geom_point() +
    geom_smooth(method = "lm") +
    stat_cor() +
    scale_x_continuous(name = "Duration (Seconds)") +
    scale_y_continuous(name = "Standard Score") +
    facet_grid(measure ~ tobii_indicator, scales = "free_x")
```

\newpage

### Average gaze time by overall direct indicators score

I set out to examine average gaze time by instructed item score specifically. However, out of the 14 participants who got at least one instructed item wrong, only 4 had eye-tracking data. Only 1 participant who got both instructed items wrong had eye-tracking data.

To maximize data availability, I've instead plotted gaze time by the overall direct indicators score instead. Again, there are 34 participants who completed all direct indicator measures _and_ have eyetracking data.

```{r, warning = F}
df %>%
  filter(!is.na(direct)) %>%
  group_by(direct) %>%
  mutate(directWithLabel = paste0(direct, " (n=", sum(!is.na(direct) & !is.na(tobii.avgQTextFixationTime)), ")")) %>%
  ggplot(aes(as.character(directWithLabel), tobii.avgQTextFixationTime)) +
    geom_boxplot() +
    scale_x_discrete(name = "Direct Indicators Score") +
    scale_y_continuous(name = "Average Question Text Fixation Duration")
```

\newpage

### Participant Characteristics by Response/Fixation Time Quartiles

### Average Question Text Fixation Time

```{r, warning = F}
df %>%
  group_by(tobii.avgQTextFixationTime_quant) %>%
  summarise(n = n(),
            pctFemale = mean(gender == 2, na.rm = T),
            medianAge = median(age, na.rm = T),
            averageRawWJScore = mean(readingLevelMean, na.rm = T),
            instructed = mean(instructed, na.rm = T),
            recall = mean(recall, na.rm = T),
            rumRaisin = mean(rumRaisin, na.rm = T),
            effort = mean(effort, na.rm = T),
            directOverall = mean(direct, na.rm = T)) %>%
  pivot_longer(n:directOverall) %>%
  pivot_wider(id_cols = name,
              names_from = tobii.avgQTextFixationTime_quant, 
              values_from = value) %>%
  kable(digits = 2)
```

### Average Question Duration

```{r, warning = F}
df %>%
  group_by(tobii.avgQuestionDuration_quant) %>%
  summarise(n = n(),
            pctFemale = mean(gender == 2, na.rm = T),
            medianAge = median(age, na.rm = T),
            averageRawWJScore = mean(readingLevelMean, na.rm = T),
            instructed = mean(instructed, na.rm = T),
            recall = mean(recall, na.rm = T),
            rumRaisin = mean(rumRaisin, na.rm = T),
            effort = mean(effort, na.rm = T),
            directOverall = mean(direct, na.rm = T)) %>%
  pivot_longer(n:directOverall) %>%
  pivot_wider(id_cols = name,
              names_from = tobii.avgQuestionDuration_quant, 
              values_from = value) %>%
  kable(digits = 2)
```

\newpage

### Stepwise Introduction of Response/Fixation Time * Reading Level Interaction in Predicting Direct Measures

### Average Question Text Fixation Time

Average question text fixation time alone is a strong predictor of a participant's direct indicator score, but this is moderated by reading level. However, once an interaction is introduced, all three predictors become significant again (and the R^2 improves).

```{r, results = "asis"}
report_regression <- function(model, ...){
  if(knitr::is_html_output()){
    require(texreg)
    htmlreg(model, custom.note="%stars. htmlreg", ...)
  } else if(knitr::is_latex_output()){
    require(stargazer)
    stargazer(model, notes="stargazer html", single.row=T, header=F, omit.table.layout = "nml", ...)
  } else {
   print("This only works with latex and html output") 
  }
}

lm(data = df,
   direct ~ tobii.avgQTextFixationTime) %>%
  report_regression()

lm(data = df,
   direct ~ tobii.avgQTextFixationTime + tobii.pctValidGazeSamples + readingLevelMean)%>%
  report_regression()

lm(data = df,
   direct ~ tobii.avgQTextFixationTime + tobii.pctValidGazeSamples + readingLevelMean + (tobii.avgQTextFixationTime * readingLevelMean))%>%
  report_regression()
```

\newpage

### Average Question Duration

A similar, but weaker, pattern can be seen with average question duration.

```{r, results = "asis"}
lm(data = df,
   direct ~ tobii.avgQuestionDuration) %>%
  report_regression()

lm(data = df,
   direct ~ tobii.avgQuestionDuration + readingLevelMean)%>%
  report_regression()

lm(data = df,
   direct ~ tobii.avgQuestionDuration + readingLevelMean + (tobii.avgQuestionDuration * readingLevelMean)) %>%
  report_regression()
```

\newpage

Interaction plots for relationships on previous two pages:

```{r, echo = F, fig.height = 3}
lm(data = df,
   direct ~ tobii.avgQTextFixationTime + tobii.pctValidGazeSamples + readingLevelMean + (tobii.avgQTextFixationTime * readingLevelMean)) %>%
  interactions::interact_plot(pred = tobii.avgQTextFixationTime, modx = readingLevelMean)
```

```{r, echo = F, fig.height = 3}
lm(data = df,
   direct ~ tobii.avgQuestionDuration + readingLevelMean + (tobii.avgQuestionDuration * readingLevelMean)) %>%
  interactions::interact_plot(pred = tobii.avgQuestionDuration, modx = readingLevelMean)
```